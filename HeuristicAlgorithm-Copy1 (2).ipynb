{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "592e7641",
   "metadata": {
    "gather": {
     "logged": 1674397164417
    }
   },
   "outputs": [],
   "source": [
    "# This program performs Heurstic Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98663eb6",
   "metadata": {
    "gather": {
     "logged": 1674397164869
    }
   },
   "outputs": [],
   "source": [
    "# Loading the relevant libraries\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import SuitabilityCode as SC\n",
    "import processing_utilities as pu\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "627c02da",
   "metadata": {
    "gather": {
     "logged": 1674397165794
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.47.0 to work with eunmldevamlwsgom\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Dataset, Environment, Datastore\n",
    "from azureml.data.datapath import DataPath\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "454fd2af",
   "metadata": {
    "gather": {
     "logged": 1674397167921
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the datastores available\n",
    "dataset = Dataset.get_by_name(ws, name='Auger_Backlog')\n",
    "rawdf = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8c018d7",
   "metadata": {
    "gather": {
     "logged": 1674397168102
    }
   },
   "outputs": [],
   "source": [
    "# Configuration Settings\n",
    "# Merging with suitability code or just use raw file\n",
    "is_suitability_code_integration = 'True'\n",
    "assetname = 'Auger'\n",
    "totalweeks = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1ab5b2e",
   "metadata": {
    "gather": {
     "logged": 1674397169121
    }
   },
   "outputs": [],
   "source": [
    "# rawfile = r'C:\\Users\\S.Chandrasekaran5\\OneDrive - Shell\\Documents\\Work\\Preventive Maintenace Optimization\\VEGA\\MILP2\\GOM\\Sprint 8\\Ursa Backlog 11-22-22.xlsx'\n",
    "# suitabilitycodefile = r'C:\\Users\\S.Chandrasekaran5\\OneDrive - Shell\\Documents\\Work\\Preventive Maintenace Optimization\\VEGA\\MILP2\\GOM\\Sprint 8\\Ursa Sutibality Codes.xlsx'\n",
    "# process_step_file = r'C:\\Users\\S.Chandrasekaran5\\OneDrive - Shell\\Documents\\Work\\Preventive Maintenace Optimization\\VEGA\\MILP2\\GOM\\Sprint 8\\BAT Tool Source.xlsx'\n",
    "# Process step File needed to map the code\n",
    "process_step_file = 'BAT Tool Source.csv'\n",
    "\n",
    "rawdf['UpdatedWorkCenter'] = rawdf['WORK_CENTER_DESCRIPTION']\n",
    "rawdf.rename(columns = {'CONCAT_USER_STATUS':'Order User Status'}, inplace = True)\n",
    "rawdf.rename(columns = {'WORK_ORDER_TYPE_CODE':'Order Type'}, inplace = True)\n",
    "rawdf.rename(columns = {'PLANNED_WORK':'Work'}, inplace = True)\n",
    "rawdf.rename(columns = {'BASIC_START_DATE':'Earliest start date'}, inplace = True)\n",
    "rawdf.rename(columns = {'PRIORITY_CODE':'Priority'}, inplace = True)\n",
    "rawdf.rename(columns = {'LATEST_ALLOWABLE_FINISH_DATE':'Latest Allowed Finish Date'}, inplace = True)\n",
    "rawdf.rename(columns = {'WORK_ORDER_SRC_ID':'Order'}, inplace = True)\n",
    "\n",
    "if is_suitability_code_integration =='True':\n",
    "    # Merging Suitability and updating work centers\n",
    "    rawdf = SC.integrate_with_suitabilitycode(rawdf,assetname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "168ebd85",
   "metadata": {
    "gather": {
     "logged": 1674397169396
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "PS LEVELS\n",
      "\n",
      "\n",
      "EXEC    6728\n",
      "PS-1    2113\n",
      "PS-2    1706\n",
      "PS-4    1181\n",
      "PS-5     544\n",
      "PS-3     109\n",
      "Name: PSLevel, dtype: int64\n",
      "Nulls :10\n"
     ]
    }
   ],
   "source": [
    "# Adding the PS Levels\n",
    "rawdf = SC.integrate_with_process_steps(rawdf,process_step_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0308e499",
   "metadata": {
    "gather": {
     "logged": 1674397169774
    }
   },
   "outputs": [],
   "source": [
    "# Weekday Thursday = 3\n",
    "# Weekday Wednesday = 2\n",
    "# For URSA, Weekday is thursday\n",
    "import math\n",
    "def datetime_to_previous_weekstart(original_datetime):\n",
    "    th=3\n",
    "    if pd.isnull(original_datetime):\n",
    "        return \n",
    "    if original_datetime.weekday() >=th:\n",
    "        return original_datetime + datetime.timedelta(days=th-original_datetime.weekday())\n",
    "    else:\n",
    "        return original_datetime + datetime.timedelta(days=-th-1-original_datetime.weekday())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fca4353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the capacity for URSA for the critical work crafts\n",
    "if assetname=='URSA':\n",
    "    capacityfile_withpath = 'ursa_capacity.csv'\n",
    "if assetname=='Olympus':\n",
    "    capacityfile_withpath = 'Olympus_capacity.csv'\n",
    "if assetname=='Auger':\n",
    "    capacityfile_withpath = 'Auger_capacity.csv'\n",
    "# capacity = pu.load_capacity_info(capacityfile_withpath)\n",
    "# capacity\n",
    "# capacitydf = pd.DataFrame(index = range(0,totalweeks),columns=arr)\n",
    "# for cnt in arr:\n",
    "#     capacitydf[cnt] = capacity[cnt]\n",
    "capacitydf = pd.read_csv(capacityfile_withpath)\n",
    "capacitydf.set_index(['Week'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f0f96e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Order</th>\n",
       "      <th>FACILITY_ID</th>\n",
       "      <th>PLANNER_GROUP_CODE</th>\n",
       "      <th>MAINTENANCE_PLANNER_GROUP_NAME</th>\n",
       "      <th>ASSET_DOMAIN_CODE</th>\n",
       "      <th>WBS_ID</th>\n",
       "      <th>WBS_CODE</th>\n",
       "      <th>WORK_ORDER_NAME</th>\n",
       "      <th>Earliest start date</th>\n",
       "      <th>...</th>\n",
       "      <th>SuitabilityCode</th>\n",
       "      <th>UpdatedWorkCenter</th>\n",
       "      <th>OT</th>\n",
       "      <th>Status</th>\n",
       "      <th>EXEC</th>\n",
       "      <th>WP</th>\n",
       "      <th>ZPM</th>\n",
       "      <th>SFIX</th>\n",
       "      <th>Code</th>\n",
       "      <th>PSLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81897272</td>\n",
       "      <td>000029228140</td>\n",
       "      <td>3236971.0</td>\n",
       "      <td>426</td>\n",
       "      <td>Auger</td>\n",
       "      <td>AD0285</td>\n",
       "      <td>825622</td>\n",
       "      <td>00091910</td>\n",
       "      <td>CAIR2745 Hot Work Replace Sewage Overboa</td>\n",
       "      <td>2025-12-25</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Construction (MainWorkCenter)</td>\n",
       "      <td>C</td>\n",
       "      <td>R</td>\n",
       "      <td>F</td>\n",
       "      <td>O</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>CRFOFA</td>\n",
       "      <td>PS-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88944962</td>\n",
       "      <td>000060117152</td>\n",
       "      <td>3236971.0</td>\n",
       "      <td>426</td>\n",
       "      <td>Auger</td>\n",
       "      <td>AD0285</td>\n",
       "      <td>825622</td>\n",
       "      <td>00091910</td>\n",
       "      <td>Replace MBV 430 Block Valves</td>\n",
       "      <td>2023-05-04</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Benoit, Donnie</td>\n",
       "      <td>C</td>\n",
       "      <td>R</td>\n",
       "      <td>F</td>\n",
       "      <td>O</td>\n",
       "      <td>Z</td>\n",
       "      <td>A</td>\n",
       "      <td>CRFOZA</td>\n",
       "      <td>PS-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92726722</td>\n",
       "      <td>000060495948</td>\n",
       "      <td>3236971.0</td>\n",
       "      <td>426</td>\n",
       "      <td>Auger</td>\n",
       "      <td>AD0285</td>\n",
       "      <td>825622</td>\n",
       "      <td>00091910</td>\n",
       "      <td>CAIR6217 - Defective Handrail(s) UD SE 2</td>\n",
       "      <td>2023-09-25</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Construction (MainWorkCenter)</td>\n",
       "      <td>C</td>\n",
       "      <td>R</td>\n",
       "      <td>F</td>\n",
       "      <td>W</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>CRFWFA</td>\n",
       "      <td>PS-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96705832</td>\n",
       "      <td>000060894488</td>\n",
       "      <td>3236971.0</td>\n",
       "      <td>426</td>\n",
       "      <td>Auger</td>\n",
       "      <td>AD0285</td>\n",
       "      <td>825622</td>\n",
       "      <td>00091910</td>\n",
       "      <td>Repair Grounding Cables on PRT's</td>\n",
       "      <td>2025-12-25</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Auger GIS Instrumentation</td>\n",
       "      <td>C</td>\n",
       "      <td>R</td>\n",
       "      <td>F</td>\n",
       "      <td>O</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>CRFOFA</td>\n",
       "      <td>PS-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97427852</td>\n",
       "      <td>000060966776</td>\n",
       "      <td>3236971.0</td>\n",
       "      <td>426</td>\n",
       "      <td>Auger</td>\n",
       "      <td>AD0285</td>\n",
       "      <td>825622</td>\n",
       "      <td>00091910</td>\n",
       "      <td>PBE-271 Engine Corrosion Repair</td>\n",
       "      <td>2023-05-16</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EXT SVS-For PM CNF-Call Out</td>\n",
       "      <td>C</td>\n",
       "      <td>R</td>\n",
       "      <td>F</td>\n",
       "      <td>O</td>\n",
       "      <td>Z</td>\n",
       "      <td>A</td>\n",
       "      <td>CRFOZA</td>\n",
       "      <td>PS-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12386</th>\n",
       "      <td>4649612652</td>\n",
       "      <td>000062683447</td>\n",
       "      <td>3236971.0</td>\n",
       "      <td>426</td>\n",
       "      <td>Auger</td>\n",
       "      <td>AD0285</td>\n",
       "      <td>825622</td>\n",
       "      <td>00091910</td>\n",
       "      <td>2W Blowout Preventer Pressure Test</td>\n",
       "      <td>2023-06-14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Auger H &amp; P Drilling</td>\n",
       "      <td>P</td>\n",
       "      <td>R</td>\n",
       "      <td>E</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>PREFFA</td>\n",
       "      <td>EXEC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12387</th>\n",
       "      <td>4649615712</td>\n",
       "      <td>000062683753</td>\n",
       "      <td>3236971.0</td>\n",
       "      <td>426</td>\n",
       "      <td>Auger</td>\n",
       "      <td>AD0285</td>\n",
       "      <td>825622</td>\n",
       "      <td>00091910</td>\n",
       "      <td>WK Single Fall Lifeboat Inspection</td>\n",
       "      <td>2023-06-15</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Electrician</td>\n",
       "      <td>P</td>\n",
       "      <td>R</td>\n",
       "      <td>E</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>PREFFA</td>\n",
       "      <td>EXEC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12388</th>\n",
       "      <td>4649616992</td>\n",
       "      <td>000062683881</td>\n",
       "      <td>3236971.0</td>\n",
       "      <td>426</td>\n",
       "      <td>Auger</td>\n",
       "      <td>AD0285</td>\n",
       "      <td>825622</td>\n",
       "      <td>00091910</td>\n",
       "      <td>2Y Yokogawa Battery Replacement</td>\n",
       "      <td>2023-04-07</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ET/CAO</td>\n",
       "      <td>P</td>\n",
       "      <td>R</td>\n",
       "      <td>E</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>PREFFA</td>\n",
       "      <td>EXEC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12389</th>\n",
       "      <td>4649617382</td>\n",
       "      <td>000062683920</td>\n",
       "      <td>3236971.0</td>\n",
       "      <td>426</td>\n",
       "      <td>Auger</td>\n",
       "      <td>AD0285</td>\n",
       "      <td>826682</td>\n",
       "      <td>00092016</td>\n",
       "      <td>1100082698/Riser Cleaning</td>\n",
       "      <td>2024-10-02</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Maintenance &amp; Integrity Marine</td>\n",
       "      <td>P</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>W</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>PCFWFA</td>\n",
       "      <td>PS-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12390</th>\n",
       "      <td>4649633782</td>\n",
       "      <td>000062685442</td>\n",
       "      <td>3236971.0</td>\n",
       "      <td>426</td>\n",
       "      <td>Auger</td>\n",
       "      <td>AD0285</td>\n",
       "      <td>825622</td>\n",
       "      <td>00091910</td>\n",
       "      <td>Nitrogen Unit Auto/Off Require Seals</td>\n",
       "      <td>2023-08-02</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Electrician</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>CCFFFA</td>\n",
       "      <td>PS-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12391 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID         Order  FACILITY_ID PLANNER_GROUP_CODE  \\\n",
       "0        81897272  000029228140    3236971.0                426   \n",
       "1        88944962  000060117152    3236971.0                426   \n",
       "2        92726722  000060495948    3236971.0                426   \n",
       "3        96705832  000060894488    3236971.0                426   \n",
       "4        97427852  000060966776    3236971.0                426   \n",
       "...           ...           ...          ...                ...   \n",
       "12386  4649612652  000062683447    3236971.0                426   \n",
       "12387  4649615712  000062683753    3236971.0                426   \n",
       "12388  4649616992  000062683881    3236971.0                426   \n",
       "12389  4649617382  000062683920    3236971.0                426   \n",
       "12390  4649633782  000062685442    3236971.0                426   \n",
       "\n",
       "      MAINTENANCE_PLANNER_GROUP_NAME ASSET_DOMAIN_CODE  WBS_ID  WBS_CODE  \\\n",
       "0                              Auger            AD0285  825622  00091910   \n",
       "1                              Auger            AD0285  825622  00091910   \n",
       "2                              Auger            AD0285  825622  00091910   \n",
       "3                              Auger            AD0285  825622  00091910   \n",
       "4                              Auger            AD0285  825622  00091910   \n",
       "...                              ...               ...     ...       ...   \n",
       "12386                          Auger            AD0285  825622  00091910   \n",
       "12387                          Auger            AD0285  825622  00091910   \n",
       "12388                          Auger            AD0285  825622  00091910   \n",
       "12389                          Auger            AD0285  826682  00092016   \n",
       "12390                          Auger            AD0285  825622  00091910   \n",
       "\n",
       "                                WORK_ORDER_NAME Earliest start date  ...  \\\n",
       "0      CAIR2745 Hot Work Replace Sewage Overboa          2025-12-25  ...   \n",
       "1                  Replace MBV 430 Block Valves          2023-05-04  ...   \n",
       "2      CAIR6217 - Defective Handrail(s) UD SE 2          2023-09-25  ...   \n",
       "3              Repair Grounding Cables on PRT's          2025-12-25  ...   \n",
       "4               PBE-271 Engine Corrosion Repair          2023-05-16  ...   \n",
       "...                                         ...                 ...  ...   \n",
       "12386        2W Blowout Preventer Pressure Test          2023-06-14  ...   \n",
       "12387        WK Single Fall Lifeboat Inspection          2023-06-15  ...   \n",
       "12388           2Y Yokogawa Battery Replacement          2023-04-07  ...   \n",
       "12389                 1100082698/Riser Cleaning          2024-10-02  ...   \n",
       "12390      Nitrogen Unit Auto/Off Require Seals          2023-08-02  ...   \n",
       "\n",
       "      SuitabilityCode               UpdatedWorkCenter OT Status EXEC WP ZPM  \\\n",
       "0                 NaN   Construction (MainWorkCenter)  C      R    F  O   F   \n",
       "1                35.0                  Benoit, Donnie  C      R    F  O   Z   \n",
       "2                 NaN   Construction (MainWorkCenter)  C      R    F  W   F   \n",
       "3                 NaN       Auger GIS Instrumentation  C      R    F  O   F   \n",
       "4                 NaN     EXT SVS-For PM CNF-Call Out  C      R    F  O   Z   \n",
       "...               ...                             ... ..    ...  ... ..  ..   \n",
       "12386             NaN            Auger H & P Drilling  P      R    E  F   F   \n",
       "12387            15.0                     Electrician  P      R    E  F   F   \n",
       "12388             5.0                          ET/CAO  P      R    E  F   F   \n",
       "12389             NaN  Maintenance & Integrity Marine  P      C    F  W   F   \n",
       "12390            15.0                     Electrician  C      C    F  F   F   \n",
       "\n",
       "      SFIX    Code PSLevel  \n",
       "0        A  CRFOFA    PS-5  \n",
       "1        A  CRFOZA    PS-4  \n",
       "2        A  CRFWFA    PS-2  \n",
       "3        A  CRFOFA    PS-5  \n",
       "4        A  CRFOZA    PS-4  \n",
       "...    ...     ...     ...  \n",
       "12386    A  PREFFA    EXEC  \n",
       "12387    A  PREFFA    EXEC  \n",
       "12388    A  PREFFA    EXEC  \n",
       "12389    A  PCFWFA    PS-2  \n",
       "12390    A  CCFFFA    PS-1  \n",
       "\n",
       "[12391 rows x 57 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e4c7439",
   "metadata": {
    "gather": {
     "logged": 1674397170241
    }
   },
   "outputs": [],
   "source": [
    "# PreProcessing\n",
    "# URSA\n",
    "from datetime import timedelta\n",
    "\n",
    "# Interchaning Priorities\n",
    "\n",
    "rawdf['Priority'].replace('S','-1',inplace=True)\n",
    "rawdf['Priority'].replace('E','0',inplace=True)\n",
    "\n",
    "# Assigning Week Numbers to ESD\n",
    "    \n",
    "rawdf['Earliest start date'] = pd.to_datetime(rawdf['Earliest start date'],errors='coerce')\n",
    "rawdf['nearestE'] = rawdf.apply(lambda row: datetime_to_previous_weekstart(row['Earliest start date']), axis=1)\n",
    "rawdf['Total_Days'] = ( rawdf['nearestE'] - datetime_to_previous_weekstart(datetime.datetime.today()) ).dt.days +1\n",
    "rawdf['WeekNumberE'] = (rawdf['Total_Days']/7) \n",
    "rawdf['ESD_WeekNumber'] = rawdf['WeekNumberE'].apply(np.int)\n",
    "\n",
    "\n",
    "# # Assigning Week Numbers to LAFD\n",
    "\n",
    "rawdf['Latest Allowed Finish Date'] = pd.to_datetime(rawdf['Latest Allowed Finish Date'],errors='coerce')\n",
    "rawdf['nearestL'] = rawdf.apply(lambda row: datetime_to_previous_weekstart(row['Latest Allowed Finish Date']), axis=1)\n",
    "rawdf['Total_Days'] = ( rawdf['nearestL'] - datetime_to_previous_weekstart(datetime.datetime.today()) ).dt.days +1\n",
    "rawdf['WeekNumberL'] = (rawdf['Total_Days']/7) \n",
    "interindex = rawdf[~rawdf['WeekNumberL'].isnull()].index\n",
    "rawdf.loc[interindex,'LAFD_WeekNumber'] = rawdf.loc[interindex,'WeekNumberL'].apply(math.ceil)\n",
    "\n",
    "# Dropping intermediate columns so that outputs looks fine\n",
    "rawdf = rawdf.drop(['nearestE','nearestL','WeekNumberE','WeekNumberL','Total_Days'],axis=1)\n",
    "\n",
    "# Defining the scope of the problem \n",
    "# only 72FP\n",
    "ind = rawdf[ (rawdf['Order Type'] == '72FP') | (rawdf['Order Type'] == '72FC') | (rawdf['Order Type'] == 'GEN') | (rawdf['Order Type'] == 'ZADM')| (rawdf['Order Type'] == '71PO')].index\n",
    "rawdf.loc[set(rawdf.index) - set(ind),'Allocated'] = 999\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17b99d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72FP    5658\n",
       "72FC    3486\n",
       "71PO    2195\n",
       "ZADM     494\n",
       "GEN      366\n",
       "Name: Order Type, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdf[rawdf['Allocated'] != 999]['Order Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3644ca2f",
   "metadata": {
    "gather": {
     "logged": 1674397170518
    }
   },
   "outputs": [],
   "source": [
    "# Concentrating only the important WOs\n",
    "\n",
    "if assetname == 'URSA':\n",
    "    arr = ['ACR/Instrument Technician','Electrician','Mechanic','ET/CAO','Ursa Utilities Crane Mechanic','Ursa Utilities Solar Mechanic','Ursa Bilfinger Maintenance Crew']\n",
    "\n",
    "if assetname == 'Olympus':\n",
    "    arr = ['ACR/Instrument Technician','Electrician','Mechanic','ET/CAO','Crane Mechanic','Turbine Mechanic','Olympus Bilfinger Maintenance Crew']\n",
    "\n",
    "if assetname == 'Auger':\n",
    "    arr = ['ACR/Instrument Technician','Electrician','Mechanic','ET/CAO','Crane Mechanic','Turbine Mechanic','Auger Bilfinger Maintenance Crew']\n",
    "\n",
    "\n",
    "df = rawdf[rawdf['Allocated'] != 999]\n",
    "df = df.dropna(subset=['Work','Earliest start date'],axis=0)\n",
    "\n",
    "\n",
    "# Scoping the constrainer\n",
    "df = df[df['ESD_WeekNumber'] >=0 ]\n",
    "df = df[df['ESD_WeekNumber'] <=50 ]\n",
    "df = df[df['UpdatedWorkCenter'].isin(arr)]\n",
    "rawdf.loc[set(rawdf.index) - set(df.index),'Allocated'] = 999\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edbef6e7",
   "metadata": {
    "gather": {
     "logged": 1674397171030
    }
   },
   "outputs": [],
   "source": [
    "# Initial allocation\n",
    "\n",
    "df['Allocated'] = 1\n",
    "df['AllocatedReason'] = ''\n",
    "df['MoveReason'] = ''\n",
    "df['Capreqd'] = ''\n",
    "df['UnAllocatedReason'] = ''\n",
    "df['PriorityFilling'] = ''\n",
    "df['AlternateESD'] = df['ESD_WeekNumber']\n",
    "\n",
    "\n",
    "# Initialize CapcityTrackingdataframe\n",
    "capacitytrackingdf = capacitydf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89635c52",
   "metadata": {
    "gather": {
     "logged": 1674397171358
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# WORK ORDER OF INTEREST\n",
    "# psdf = SC.weekwise_pslevels(df[df['Order Type'] == '72FC'],'ESD_WeekNumber')\n",
    "# SC.plotting_bar_graph(psdf,'Original')\n",
    "# plt.savefig('orginal.png')\n",
    "# psdf = SC.weekwise_pslevels(df[df['Order Type'] == '72FP'],'ESD_WeekNumber')\n",
    "# SC.plotting_bar_graph(psdf)\n",
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6151b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert the unloading point to datetime\n",
    "# from dateutil.parser import parse\n",
    "\n",
    "# def is_date(string, fuzzy=True):\n",
    "#     \"\"\"\n",
    "#     Return whether the string can be interpreted as a date.\n",
    "\n",
    "#     :param string: str, string to check for date\n",
    "#     :param fuzzy: bool, ignore unknown tokens in string if True\n",
    "#     \"\"\"\n",
    "#     try: \n",
    "#         parse(string, fuzzy=fuzzy)\n",
    "#         return True\n",
    "\n",
    "#     except ValueError:\n",
    "#         return False\n",
    "    \n",
    "# unloadingdf = df[(df['RESERVATION_UNLOADING_POINT'].str.contains('ETA')) | (df['RESERVATION_UNLOADING_POINT'].str.contains('eta'))]    \n",
    "# for cnt in range(0,len(unloadingdf)):\n",
    "#     strtocheck = str(unloadingdf.loc[unloadingdf.index[cnt],'RESERVATION_UNLOADING_POINT'])\n",
    "#     if is_date(strtocheck) == True :\n",
    "#         df.loc[unloadingdf.index[cnt],'ETADate'] = parse(strtocheck,fuzzy=True)\n",
    "        \n",
    "# Converting ETA to Weeknumber\n",
    "        \n",
    "df['ETADate'] = pd.to_datetime(df['ETADate'],errors='coerce')\n",
    "df['nearestE'] = df.apply(lambda row: datetime_to_previous_weekstart(row['ETADate']), axis=1)\n",
    "df['Total_Days'] = ( df['nearestE'] - datetime_to_previous_weekstart(datetime.datetime.today()) ).dt.days +1\n",
    "df['WeekNumberE'] = (df['Total_Days']/7) \n",
    "interindex = df[~df['WeekNumberE'].isnull()].index\n",
    "df.loc[interindex,'ETA_WeekNumber'] = df.loc[interindex,'WeekNumberE'].apply(np.int)\n",
    "\n",
    "\n",
    "# Dropping intermediate columns so that outputs looks fine\n",
    "df = df.drop(['nearestE','WeekNumberE','Total_Days'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f6eb57",
   "metadata": {},
   "source": [
    "## ZPBL Constraint - CAM Constraint - T0 Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "514d2d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "workorder_zpbl = df[( (df['ESD_WeekNumber'] == 0) | (df['Order User Status'].str.contains('ZPBL')) | (df['Order User Status'].str.contains('CAM'))) & (df['Order Type'] == '72FC') ]['Order'].unique()\n",
    "# Stagnant df\n",
    "stagnantdf = pd.DataFrame()\n",
    "for cnt in workorder_zpbl:\n",
    "    stagnantdf = pd.concat([stagnantdf,df[df['Order'] == cnt]], axis=0)\n",
    "stagnantdf['Allocated'] = 9\n",
    "stagnantdf['AllocatedReason'] = 'ZPBL/CAM/T0 Constraint'\n",
    "\n",
    "# Reduction of Capacity by zpbl\n",
    "for i in workorder_zpbl:\n",
    "    for cnt in range(0,50):\n",
    "        for count in arr:\n",
    "            val = df[ ((df['ESD_WeekNumber']==cnt) & (df['UpdatedWorkCenter']==count) & (df['Order Type'] == '72FC') & (df['Order'] == i))]['Work'].sum()\n",
    "            capacitydf.loc[cnt,count] = capacitydf.loc[cnt,count] - val\n",
    "\n",
    "# Removing them from the df\n",
    "df=df[~df.index.isin(stagnantdf.index)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5539aab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update CapcityTrackingdataframe\n",
    "capacitytrackingdf = pu.update_capacity_tracking_dataframe(capacitytrackingdf, capacitydf,'_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60ecfddb",
   "metadata": {
    "gather": {
     "logged": 1674397171529
    }
   },
   "outputs": [],
   "source": [
    "# Dealing with WorkOrders\n",
    "#****************** PS COnstraints *******************\n",
    "\n",
    "listofallT4psdfwhole = df[ ((df['PSLevel'] == 'PS-1') |  (df['PSLevel'] == 'PS-2') |  (df['PSLevel'] == 'PS-3')) & (df['Order Type'] == '72FC') & (df['ESD_WeekNumber'] <= 3)]\n",
    "\n",
    "listofallT4psdfresidual = listofallT4psdfwhole[listofallT4psdfwhole['ESD_WeekNumber'] == listofallT4psdfwhole['LAFD_WeekNumber'] ]\n",
    "\n",
    "listofallT4psdf = listofallT4psdfwhole[listofallT4psdfwhole['ESD_WeekNumber'] < listofallT4psdfwhole['LAFD_WeekNumber'] ]\n",
    "listofallT4psdf['AlternateESD'] = listofallT4psdf['ESD_WeekNumber'] + np.ceil(0.8*(listofallT4psdf['LAFD_WeekNumber'] - listofallT4psdf['ESD_WeekNumber']))\n",
    "listofallT4psdf.loc[listofallT4psdf.index,'MoveReason'] = 'Changed due to PS 1-3'\n",
    "listofallT4psdf.loc[listofallT4psdf.index,'Allocated'] = 2\n",
    "\n",
    "# Reduce the capacity in the moved week.\n",
    "for i in listofallT4psdf['Order'].unique():\n",
    "    for cnt in range(0,50):\n",
    "        for count in arr:\n",
    "            val = listofallT4psdf[ (listofallT4psdf['AlternateESD']==cnt) & (listofallT4psdf['UpdatedWorkCenter']==count) & (listofallT4psdf['Order Type'] == '72FC') & listofallT4psdf['Order'] == i]['Work'].sum()\n",
    "            capacitydf.loc[cnt,count] = capacitydf.loc[cnt,count] - val\n",
    "\n",
    "# Removing them from the df\n",
    "df=df[~df.index.isin(listofallT4psdf.index)]\n",
    "\n",
    "\n",
    "\n",
    "# Moving them to alternate week - fixed case\n",
    "# processleveldf.loc[processleveldf[ processleveldf['ESD_WeekNumber'] <= 3].index,'AlternateESD'] = 5\n",
    "#****************** PS COnstraints *******************\n",
    "\n",
    "listofallT4psdfresidual.loc[listofallT4psdfresidual.index,'Allocated'] = 29\n",
    "listofallT4psdfresidual.loc[listofallT4psdfresidual.index,'PriorityFilling'] = ''\n",
    "# Removing them from the df\n",
    "df=df[~df.index.isin(listofallT4psdfresidual.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "435cba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#****************** ETA COnstraints - 2 *******************\n",
    "\n",
    "etadf1 = df[ (df['PSLevel'] == 'PS-4') & (( df['ESD_WeekNumber'] - df['ETA_WeekNumber'] ) < 3) & (df['ETA_WeekNumber'] + 3 <= df['LAFD_WeekNumber'])]\n",
    "\n",
    "etadf1['AlternateESD'] = etadf1['ETA_WeekNumber'] + 3\n",
    "etadf1['Allocated'] = 3\n",
    "etadf1['MoveReason'] = 'ETA Constraint'\n",
    "etadf1['PriorityFilling'] = ''\n",
    "\n",
    "# Reduce the capacity in the moved week.\n",
    "for i in etadf1['Order'].unique():\n",
    "    for cnt in range(0,50):\n",
    "        for count in arr:\n",
    "            val = etadf1[ (etadf1['AlternateESD']==cnt) & (etadf1['UpdatedWorkCenter']==count) & (etadf1['Order Type'] == '72FC') & etadf1['Order'] == i]['Work'].sum()\n",
    "            capacitydf.loc[cnt,count] = capacitydf.loc[cnt,count] - val\n",
    "\n",
    "# Removing them from the df\n",
    "df=df[~df.index.isin(etadf1.index)]\n",
    "\n",
    "# Residual \n",
    "etadf1Residual = df[ (df['PSLevel'] == 'PS-4') & (( df['ESD_WeekNumber'] - df['ETA_WeekNumber'] ) <3) ]\n",
    "etadf1Residual['AlternateESD'] = etadf1Residual['ESD_WeekNumber'] \n",
    "etadf1Residual['Allocated'] = 39\n",
    "etadf1Residual['PriorityFilling'] = ''\n",
    "# Removing them from the df\n",
    "df=df[~df.index.isin(etadf1Residual.index)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "baef4ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update CapcityTrackingdataframe\n",
    "capacitytrackingdf = pu.update_capacity_tracking_dataframe(capacitytrackingdf, capacitydf,'_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8be1e8dc",
   "metadata": {
    "gather": {
     "logged": 1674397172426
    }
   },
   "outputs": [],
   "source": [
    "# Reduction of Capacity by PMs, PO , GEN, ZADM\n",
    "for cnt in range(0,50):\n",
    "    for count in arr:\n",
    "        val = df[ (df['ESD_WeekNumber']==cnt) & (df['UpdatedWorkCenter']==count) & ( (df['Order Type'] == '72FP') | (df['Order Type'] == 'GEN') | (df['Order Type'] == 'ZADM')| (df['Order Type'] == '71PO'))]['Work'].sum()\n",
    "        capacitydf.loc[cnt,count] = capacitydf.loc[cnt,count] - val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7ff2a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update CapcityTrackingdataframe\n",
    "capacitytrackingdf = pu.update_capacity_tracking_dataframe(capacitytrackingdf, capacitydf,'_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "575dce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capacity Requirement for the CMs\n",
    "CMcapacityreqdf = pd.DataFrame()\n",
    "for cnt in range(0,50):\n",
    "    for count in arr:\n",
    "        val = df[ (df['ESD_WeekNumber']==cnt) & (df['UpdatedWorkCenter']==count) &  (df['Order Type'] == '72FC') ]['Work'].sum()\n",
    "        CMcapacityreqdf.loc[cnt,count] = val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e50b895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update CapcityTrackingdataframe\n",
    "capacitytrackingdf = pu.update_capacity_tracking_dataframe(capacitytrackingdf, CMcapacityreqdf,'_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ed2effe",
   "metadata": {
    "gather": {
     "logged": 1674397172596
    }
   },
   "outputs": [],
   "source": [
    "# Seggregating CM versus the rest stagnant order types\n",
    "\n",
    "FCdf = df[df['Order Type'] == '72FC']\n",
    "FPdf = df[ ((df['Order Type'] == '72FP') | (df['Order Type'] == 'GEN') | (df['Order Type'] == 'ZADM')| (df['Order Type'] == '71PO'))]\n",
    "FPdf['Allocated']=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b6c01a6",
   "metadata": {
    "gather": {
     "logged": 1674397173168
    }
   },
   "outputs": [],
   "source": [
    "def perform_allocation(tempdf,FCdf,weeknumber,capacitydf):\n",
    "    \n",
    "    FCdf.loc[tempdf.index,'Allocated'] = 0\n",
    "    FCdf.loc[tempdf.index,'AlternateESD'] = weeknumber\n",
    "    # Reduce the capacity\n",
    "    for gg in tempdf['UpdatedWorkCenter'].unique():\n",
    "        \n",
    "        FCdf.loc[tempdf[tempdf['UpdatedWorkCenter'] == gg].index,'AllocatedReason'] = 'Available Capacity for this WorkCenter in the Week :' + str(weeknumber) + ': '+ str(capacitydf.loc[weeknumber,gg]) +',Required Capacity for this WorkCenter in the Week :' +str(weeknumber) + ' : '+ str(tempdf[tempdf['UpdatedWorkCenter'] == gg]['Work'].sum()) + '. LAFD Constraint Satisified. Bundling of WO Satsified'\n",
    "        capacitydf.loc[weeknumber,gg] = capacitydf.loc[weeknumber,gg] - tempdf[tempdf['UpdatedWorkCenter'] == gg]['Work'].sum()\n",
    "         \n",
    "        \n",
    "    return FCdf,capacitydf\n",
    "            \n",
    "def iscapacityavailableforWO(capacitydf,tempdf,weeknumber):\n",
    "\n",
    "    doable = 0\n",
    "    for gg in tempdf['UpdatedWorkCenter'].unique():\n",
    "#         print(weeknumber,gg,tempdf[tempdf['UpdatedWorkCenter'] == gg]['Work'].sum(),capacitydf.loc[weeknumber,gg])\n",
    "        if tempdf[tempdf['UpdatedWorkCenter'] == gg]['Work'].sum() <= capacitydf.loc[weeknumber,gg] :\n",
    "            doable = doable + 1           \n",
    "        else:\n",
    "            return False\n",
    "    if doable > 0 :\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "def reasonfornotfilling(tempdf,FCdf,weeknumber,capacitydf):\n",
    "    for gg in tempdf['UpdatedWorkCenter'].unique():\n",
    "        FCdf.loc[tempdf[tempdf['UpdatedWorkCenter'] == gg].index,'MoveReason'] = FCdf.loc[tempdf[tempdf['UpdatedWorkCenter'] == gg].index,'MoveReason'] + 'Available Capacity in Week ' +str(weeknumber) +': ' +str(capacitydf.loc[weeknumber,gg]) +',Required Capacity in Week '+str(weeknumber) + ':' + str(tempdf[tempdf['UpdatedWorkCenter'] == gg]['Work'].sum())\n",
    "        FCdf.loc[tempdf[tempdf['UpdatedWorkCenter'] == gg].index,'Capreqd'] = str(tempdf[tempdf['UpdatedWorkCenter'] == gg]['Work'].sum())\n",
    "        \n",
    "    return FCdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1587ca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updatevalidation_matrix_before(validation_matrix,tempdf,capdf,weekno,linenumber):\n",
    "\n",
    "\n",
    "    for gg in tempdf['UpdatedWorkCenter'].unique():\n",
    "        validation_matrix.loc[linenumber,'Week'] = weekno\n",
    "        validation_matrix.loc[linenumber,'WO'] = tempdf['Order'].unique()[0]\n",
    "        validation_matrix.loc[linenumber,'WorkCraft'] = gg\n",
    "        validation_matrix.loc[linenumber,'RequiredCapacity'] = tempdf[tempdf['UpdatedWorkCenter'] == gg]['Work'].sum()\n",
    "        validation_matrix.loc[linenumber,'AvailableCapacity'] = capdf.loc[weekno,gg]\n",
    "        validation_matrix.loc[linenumber,'PriorityWO'] =  tempdf.loc[tempdf.index[0],'Priority']\n",
    "        validation_matrix.loc[linenumber,'ESD_WeekNumber'] = tempdf.loc[tempdf.index[0],'ESD_WeekNumber']\n",
    "        validation_matrix.loc[linenumber,'LAFD_WeekNumber'] = tempdf.loc[tempdf.index[0],'LAFD_WeekNumber']\n",
    "        linenumber=linenumber+1\n",
    "        \n",
    "    \n",
    "    return validation_matrix,linenumber\n",
    "\n",
    "def updatevalidation_matrix_after(valdf,tempdf,capdf,weekno,linenumber,priorityfilling):\n",
    "    \n",
    "    for gg in tempdf['UpdatedWorkCenter'].unique():\n",
    "        valdf.loc[linenumber,'AvailableCapacity_afterallocation'] = capdf.loc[weekno,gg]\n",
    "        valdf.loc[linenumber,'priorityfilling'] = priorityfilling   \n",
    "        linenumber=linenumber+1\n",
    "        \n",
    "\n",
    "\n",
    "    return valdf\n",
    "          \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "887d5564",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_matrix = pd.DataFrame(columns=['Week','WO','WorkCraft','RequiredCapacity','AvailableCapacity','AvailableCapacity_afterallocation','priorityfilling','ESD_WeekNumber','LAFD_WeekNumber'])\n",
    "uplineno=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d038f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOr Vignesh Math Optimization\n",
    "Vigneshdf = FCdf[['Order','PLANNER_GROUP_CODE','MAINTENANCE_PLANNER_GROUP_NAME','Earliest start date','Order Type','Latest Allowed Finish Date','UpdatedWorkCenter','Priority','Work','WORK_ACTIVITY_NUMBER']]\n",
    "Vigneshdf.rename(columns = {'UpdatedWorkCenter':'MAIN_WORK_CENTER_DESCRIPTION'},inplace=True)\n",
    "Vigneshdf.to_csv('MathOptimization_Input_7_March_2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5238cfc3",
   "metadata": {
    "gather": {
     "logged": 1674397173883
    }
   },
   "outputs": [],
   "source": [
    "for cnt in range(0,50):\n",
    "#     print(cnt)\n",
    "    k=1\n",
    "    refdf = FCdf[ (FCdf['ESD_WeekNumber'] <= cnt) & (FCdf['LAFD_WeekNumber'] >= cnt)]\n",
    "    refdf = refdf[refdf['Allocated']==1]\n",
    "    refdf = refdf[ (refdf['ESD_WeekNumber']) <= (refdf['LAFD_WeekNumber'])]\n",
    "    refdf= refdf.sort_values(by = ['Priority','LAFD_WeekNumber','Work'], ascending=[True,True,True])\n",
    "\n",
    "    for count in refdf['Order'].unique():    \n",
    "        iscapacityavailable = iscapacityavailableforWO(capacitydf,refdf[refdf['Order']==count],cnt) \n",
    "        \n",
    "        lineno = uplineno\n",
    "        validation_matrix,uplineno = updatevalidation_matrix_before(validation_matrix,refdf[refdf['Order']==count],capacitydf,cnt,uplineno)\n",
    "        \n",
    "        if  iscapacityavailable == True:\n",
    "            curr_wo = refdf[refdf['Order']==count]\n",
    "            FCdf,capacitydf = perform_allocation(curr_wo,FCdf,cnt,capacitydf)\n",
    "            FCdf.loc[curr_wo.index,'PriorityFilling'] = k\n",
    "            \n",
    "            validation_matrix = updatevalidation_matrix_after(validation_matrix,refdf[refdf['Order']==count],capacitydf,cnt,lineno,k)\n",
    "            \n",
    "            k=k+1\n",
    "        else:\n",
    "            curr_wo = refdf[refdf['Order']==count]\n",
    "            FCdf =  reasonfornotfilling(curr_wo,FCdf,cnt,capacitydf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39436a6e",
   "metadata": {
    "gather": {
     "logged": 1674397174533
    }
   },
   "outputs": [],
   "source": [
    "# Reason for Unallocated Status\n",
    "unallocdf = FCdf[FCdf['Allocated']==1]\n",
    "\n",
    "# FCdf.loc[FCdf['ESD_WeekNumber'].isnull().index,'UnAllocatedReason'] = ' LAFD lesser than ESD. This item is Unscheduled'\n",
    "# FCdf.loc[FCdf['LAFD_WeekNumber'].isnull().index,'UnAllocatedReason'] = ' LAFD lesser than ESD. This item is Unscheduled'\n",
    "\n",
    "FCdf.loc[unallocdf.index,'UnAllocatedReason'] = ' WO Bundling with the available capacity not Possible within LAFD. This item is Unscheduled'\n",
    "ind = unallocdf[unallocdf['ESD_WeekNumber'] > unallocdf['LAFD_WeekNumber']].index\n",
    "FCdf.loc[ind,'UnAllocatedReason'] = ' LAFD lesser than ESD. This item is Unscheduled'\n",
    "# ind = unallocdf[unallocdf['MoveReason'] != ''].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4bcb0c7",
   "metadata": {
    "gather": {
     "logged": 1674397177254
    }
   },
   "outputs": [],
   "source": [
    "# Going back to df \n",
    "\n",
    "df.loc[FCdf.index,:] = FCdf.loc[FCdf.index,:]\n",
    "df = pd.concat([df,listofallT4psdf], axis=0)\n",
    "# df = pd.concat([df,etadf], axis=0)\n",
    "df = pd.concat([df,etadf1], axis=0)\n",
    "# df = pd.concat([df,etadf3], axis=0)\n",
    "df = pd.concat([df,etadf1Residual], axis=0)\n",
    "# df = pd.concat([df,etadf3Residual], axis=0)\n",
    "df = pd.concat([df,listofallT4psdfresidual], axis=0)\n",
    "\n",
    "df = pd.concat([df,stagnantdf], axis=0)\n",
    "df.loc[FPdf.index,:] = FPdf.loc[FPdf.index,:]\n",
    "\n",
    "df.loc[:,'MoveReason']  = ' '\n",
    "\n",
    "inde = df[ ((df['ESD_WeekNumber'] != df['AlternateESD']) & (df['Allocated'] == 0) & (df['AlternateESD'] <= df['LAFD_WeekNumber']) ) ].index\n",
    "df.loc[inde,'MovedOut'] = 1\n",
    "df.loc[inde,'MoveReason']  = 'Moved from the scheduled week to meet the capacity for the WO' \n",
    "\n",
    "inde = df[ (df['Allocated'] == 2) ].index\n",
    "df.loc[inde,'MovedOut'] = 1\n",
    "df.loc[inde,'MoveReason']  = 'PS 1-3 Constraint. Any PS 1-3 WOs moved to 0.8 times LAFD'\n",
    "\n",
    "inde = df[ (df['Allocated'] == 3) ].index\n",
    "df.loc[inde,'MovedOut'] = 1\n",
    "df.loc[inde,'MoveReason']  = 'ETA Constraint '\n",
    "\n",
    "inde = df[ (df['Allocated'] == 39) ].index\n",
    "df.loc[inde,'MoveReason']  = 'ETA-Unmovable'\n",
    "\n",
    "inde = df[ (df['Allocated'] == 29) ].index\n",
    "df.loc[inde,'MoveReason']  = 'PS1-3 Unmovable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9c9d913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capacity Requirement for the CMs after optimization\n",
    "CMcapacityreqdf_after = pd.DataFrame()\n",
    "for cnt in range(0,50):\n",
    "    for count in arr:\n",
    "        val = df[ (df['AlternateESD']==cnt) & (df['UpdatedWorkCenter']==count)& (df['Allocated']==0) &  (df['Order Type'] == '72FC') ]['Work'].sum()\n",
    "        CMcapacityreqdf_after.loc[cnt,count] = val\n",
    "\n",
    "# Update CapcityTrackingdataframe\n",
    "capacitytrackingdf = pu.update_capacity_tracking_dataframe(capacitytrackingdf, CMcapacityreqdf_after,'_5')\n",
    "\n",
    "capacitytrackingdf.to_csv('CapacityTracking.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d18bd64a",
   "metadata": {
    "gather": {
     "logged": 1674397178525
    }
   },
   "outputs": [],
   "source": [
    "addncols = list(set(df.columns)-set(rawdf.columns))\n",
    "for cnt in addncols:\n",
    "    rawdf[cnt]=''\n",
    "rawdf.loc[df.index,:] = df.loc[df.index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1b8a8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rawdf.loc[:,'MAIN_WORK_CENTER_DESCRIPTION'] = rawdf.loc[:,'UpdatedWorkCenter']\n",
    "# rawdf.rename(column = {'Order User Status':'CONCAT_USER_STATUS'}, inplace = True)\n",
    "# rawdf.rename(columns = {'Order Type':'WORK_ORDER_TYPE_CODE'}, inplace = True)\n",
    "# rawdf.rename(columns = {'Work':'PLANNED_WORK'}, inplace = True)\n",
    "# rawdf.rename(columns = {'Earliest start date':'BASIC_START_DATE'}, inplace = True)\n",
    "# rawdf.rename(columns = {'Priority':'PRIORITY_CODE'}, inplace = True)\n",
    "# rawdf.rename(columns = {'Latest Allowed Finish Date':'LATEST_ALLOWABLE_FINISH_DATE'}, inplace = True)\n",
    "# rawdf.rename(columns = {'Order':'WORK_ORDER_SRC_ID'},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af49c122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation of Allocated Codes\n",
    "rawdf['Constraint'] = ''\n",
    "rawdf.loc[rawdf[rawdf['Allocated']==0].index,'Constraint'] = 'No Change - Schedulable'\n",
    "rawdf.loc[rawdf[ (rawdf['Allocated']==0) & (rawdf['MovedOut']==1) ].index,'Constraint'] = 'Change - Capacity Constraint overcome by Moving WO'\n",
    "inn =  rawdf[(rawdf['Allocated']==1) & (rawdf['UnAllocatedReason'].str.contains('ESD') )].index\n",
    "rawdf.loc[inn,'Constraint'] = 'No Change - LAFD / ESD Issue'\n",
    "inn =  rawdf[(rawdf['Allocated']==1) & (rawdf['UnAllocatedReason'].str.contains('Bundling') )].index\n",
    "rawdf.loc[inn,'Constraint'] = 'No Change - Capacity Constraint due to LAFD'\n",
    "rawdf.loc[rawdf[rawdf['Allocated']==39].index,'Constraint'] = 'No Change - LAFD / ESD Issue'\n",
    "rawdf.loc[rawdf[rawdf['Allocated']==29].index,'Constraint'] = 'No Change - LAFD / ESD Issue'\n",
    "rawdf.loc[rawdf[rawdf['Allocated']==2].index,'Constraint'] = 'Change - Process Level Constraint'\n",
    "rawdf.loc[rawdf[rawdf['Allocated']==3].index,'Constraint'] = 'Change - ETA Constraint'\n",
    "rawdf.loc[rawdf[rawdf['Allocated']==9].index,'Constraint'] = 'No Change - ZPBL/CAM/T0 Constraint'\n",
    "rawdf.loc[rawdf[rawdf['Allocated']==999].index,'Constraint'] = 'No Change - Out of Scope'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e106bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the Validation_Matrix\n",
    "# WOs which are Schedulable\n",
    "schwo = rawdf[rawdf['Constraint'].str.contains('Schedulable')]['Order'].unique()\n",
    "for wono in schwo:\n",
    "    ind = validation_matrix[validation_matrix['WO']==wono].index\n",
    "    validation_matrix.loc[ind,'Constraint'] = 'No Change - Schedulable'\n",
    "\n",
    "schmvwo = rawdf[rawdf['Constraint'].str.contains('Moving WO')]['Order'].unique()\n",
    "for wono in schmvwo:\n",
    "    ind = validation_matrix[validation_matrix['WO']==wono].index\n",
    "    validation_matrix.loc[ind,'Constraint'] = 'Change - Capacity Constraint overcome by Moving WO'\n",
    "    \n",
    "schimwo = rawdf[rawdf['Constraint'].str.contains('Capacity Constraint - Immovable')]['Order'].unique()\n",
    "for wono in schimwo:\n",
    "    ind = validation_matrix[validation_matrix['WO']==wono].index\n",
    "    validation_matrix.loc[ind,'Constraint'] = 'No Change - Capacity Constraint due to LAFD'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "731c378e",
   "metadata": {
    "gather": {
     "logged": 1674397178846
    }
   },
   "outputs": [],
   "source": [
    "rawdf.to_csv('AfterOptimization.csv')\n",
    "validation_matrix.to_csv('validation_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d70ec24e",
   "metadata": {
    "gather": {
     "logged": 1678982876772
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating arguments.\n",
      "Arguments validated.\n",
      "Successfully obtained datastore reference and path.\n",
      "Uploading file to managed-dataset/ce257e5f-153d-4c17-b2cb-c616b47cad8b/\n"
     ]
    },
    {
     "ename": "ExecutionError",
     "evalue": "\nError Code: ScriptExecution.ReadDataFrame.StreamAccess.Validation\nValidation Error Code: Invalid\nValidation Target: PreppyFile\nFailed Step: 0aecf2d9-0271-491a-9103-a01355f44305\nError Message: ScriptExecutionException was caused by ReadDataFrameException.\n  Failed to read Pandas DataFrame form Python host. Make sure Dataflow is created directly from the source Pandas DataFrame.\n    StreamAccessException was caused by ValidationException.\n      Trying to read an invalid file. Missing sentinel value in the beginning\n| session_id=dad8e622-9405-4350-a05b-303770cbe19f",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mExecutionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [40], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m defdatastore \u001b[38;5;241m=\u001b[39m ws\u001b[38;5;241m.\u001b[39mget_default_datastore()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Register the dataset\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTabular\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_pandas_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrawdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAfterOptimization\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAfterOptimization\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefdatastore\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/_loggerfactory.py:132\u001b[0m, in \u001b[0;36mtrack.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _LoggerFactory\u001b[38;5;241m.\u001b[39mtrack_activity(logger, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions) \u001b[38;5;28;01mas\u001b[39;00m al:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(al, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivity_info\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror_code\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/dataset_factory.py:655\u001b[0m, in \u001b[0;36mTabularDatasetFactory.register_pandas_dataframe\u001b[0;34m(dataframe, target, name, description, tags, show_progress)\u001b[0m\n\u001b[1;32m    653\u001b[0m dflow \u001b[38;5;241m=\u001b[39m dataprep()\u001b[38;5;241m.\u001b[39mread_pandas_dataframe(df\u001b[38;5;241m=\u001b[39msanitized_df, in_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    654\u001b[0m target_directory_path \u001b[38;5;241m=\u001b[39m DataReference(datastore\u001b[38;5;241m=\u001b[39mdatastore)\u001b[38;5;241m.\u001b[39mpath(relative_path_with_guid)\n\u001b[0;32m--> 655\u001b[0m \u001b[43mdflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_to_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_directory_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_local\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m console(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessfully uploaded file to datastore.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    658\u001b[0m console(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating and registering a new dataset.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/_loggerfactory.py:219\u001b[0m, in \u001b[0;36mtrack.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _LoggerFactory\u001b[38;5;241m.\u001b[39mtrack_activity(logger, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, DEFAULT_ACTIVITY_TYPE, custom_dimensions) \u001b[38;5;28;01mas\u001b[39;00m activityLogger:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(activityLogger, ACTIVITY_INFO_KEY) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, ERROR_CODE_KEY):\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/dataflow.py:636\u001b[0m, in \u001b[0;36mDataflow.run_local\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tracer\u001b[38;5;241m.\u001b[39mstart_as_current_span(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataflow.run_local\u001b[39m\u001b[38;5;124m'\u001b[39m, parent) \u001b[38;5;28;01mas\u001b[39;00m span:\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing_secrets()\n\u001b[0;32m--> 636\u001b[0m     \u001b[43m_execute_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDataflow.run_local\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspan_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mto_dprep_span_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/_dataframereader.py:262\u001b[0m, in \u001b[0;36m_execute_with_fallback\u001b[0;34m(activity, dataflow_to_execute, force_clex, span_context, force_rslex, cleanup)\u001b[0m\n\u001b[1;32m    260\u001b[0m cleanup() \u001b[38;5;28;01mif\u001b[39;00m cleanup \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m     \u001b[43mclex_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    264\u001b[0m     clex_error \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/_dataframereader.py:234\u001b[0m, in \u001b[0;36m_execute_with_fallback.<locals>.clex_execute\u001b[0;34m()\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataflow\n\u001b[1;32m    233\u001b[0m activity_data \u001b[38;5;241m=\u001b[39m Dataflow\u001b[38;5;241m.\u001b[39m_dataflow_to_anonymous_activity_data(dataflow_to_execute)\n\u001b[0;32m--> 234\u001b[0m \u001b[43mdataflow_to_execute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_anonymous_activity\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mExecuteAnonymousActivityMessageArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43manonymous_activity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactivity_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspan_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspan_context\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/_aml_helper.py:38\u001b[0m, in \u001b[0;36mupdate_aml_env_vars.<locals>.decorator.<locals>.wrapper\u001b[0;34m(op_code, message, cancellation_token)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(changed) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     37\u001b[0m     engine_api_func()\u001b[38;5;241m.\u001b[39mupdate_environment_variable(changed)\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msend_message_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_token\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/engineapi/api.py:159\u001b[0m, in \u001b[0;36mEngineAPI.execute_anonymous_activity\u001b[0;34m(self, message_args, cancellation_token)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;129m@update_aml_env_vars\u001b[39m(get_engine_api)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_anonymous_activity\u001b[39m(\u001b[38;5;28mself\u001b[39m, message_args: typedefinitions\u001b[38;5;241m.\u001b[39mExecuteAnonymousActivityMessageArguments, cancellation_token: CancellationToken \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_message_channel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEngine.ExecuteActivity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/engineapi/engine.py:291\u001b[0m, in \u001b[0;36mMultiThreadMessageChannel.send_message\u001b[0;34m(self, op_code, message, cancellation_token)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[1;32m    290\u001b[0m     cancel_on_error()\n\u001b[0;32m--> 291\u001b[0m     \u001b[43mraise_engine_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43merror\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/errorhandlers.py:10\u001b[0m, in \u001b[0;36mraise_engine_error\u001b[0;34m(error_response)\u001b[0m\n\u001b[1;32m      8\u001b[0m error_code \u001b[38;5;241m=\u001b[39m error_response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merrorCode\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScriptExecution\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_code:\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ExecutionError(error_response)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_code:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ValidationError(error_response)\n",
      "\u001b[0;31mExecutionError\u001b[0m: \nError Code: ScriptExecution.ReadDataFrame.StreamAccess.Validation\nValidation Error Code: Invalid\nValidation Target: PreppyFile\nFailed Step: 0aecf2d9-0271-491a-9103-a01355f44305\nError Message: ScriptExecutionException was caused by ReadDataFrameException.\n  Failed to read Pandas DataFrame form Python host. Make sure Dataflow is created directly from the source Pandas DataFrame.\n    StreamAccessException was caused by ValidationException.\n      Trying to read an invalid file. Missing sentinel value in the beginning\n| session_id=dad8e622-9405-4350-a05b-303770cbe19f"
     ]
    }
   ],
   "source": [
    "# # Data Egestion to the current optimization blob\n",
    "defdatastore = ws.get_default_datastore()\n",
    "# Register the dataset\n",
    "ds = Dataset.Tabular.register_pandas_dataframe(\n",
    "        dataframe=rawdf, \n",
    "        name='AfterOptimization', \n",
    "        description='AfterOptimization',\n",
    "        target=defdatastore\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292f2ae3",
   "metadata": {
    "gather": {
     "logged": 1674397180203
    }
   },
   "outputs": [],
   "source": [
    "datastore = Datastore.get(ws, 'azblobsdk')\n",
    "ds = Dataset.Tabular.register_pandas_dataframe(\n",
    "        dataframe=rawdf, \n",
    "        name='AfterOptimization', \n",
    "        description='AfterOptimization',\n",
    "        target=datastore\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca700e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
